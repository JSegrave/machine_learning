{
 "metadata": {
  "name": "",
  "signature": "sha256:2856ffce8c4e5f5352a3bcd4bc20093a821af8e62a14e1352331cb013c3c4f7f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#grid.grid_scores_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# special IPython command to prepare the notebook for matplotlib\n",
      "%matplotlib inline\n",
      "from matplotlib import pyplot\n",
      "from matplotlib import pylab\n",
      "\n",
      "data_labels, markers, colours, alphas = [0, 1], ['o', 'o'], ['b', 'r'], [0.3, 0.6]\n",
      "\n",
      "def scatterplot(xaxis, yaxis, y, title = '', xlabel = 'X', ylabel = 'Y'):\n",
      "    for label, marker, colour, a in zip(data_labels, markers, colours, alphas):\n",
      "        pyplot.scatter(xaxis[y == label], yaxis[y == label], c=colour, s = 30, cmap=plt.cm.bwr, marker=marker, alpha=a, edgecolors='none')\n",
      "    pyplot.xlabel(xlabel)\n",
      "    pyplot.ylabel(ylabel)\n",
      "    pyplot.title(title)\n",
      "    pyplot.legend(loc='best')\n",
      "    pyplot.show()\n",
      "\n",
      "# Attributed to \"Building Machine Learning Systems with Python\", 2013 Richert, W. and Coelho, L., Packt Publishing\n",
      "def plot_precision_recall_curve(auc_score, precision, recall):\n",
      "    pylab.clf()\n",
      "    pylab.figure(num=None, figsize=(5, 4))\n",
      "    pylab.grid(True)\n",
      "    pylab.fill_between(recall, precision, alpha=0.5)\n",
      "    pylab.plot(recall, precision, lw=1)\n",
      "    pylab.xlim([0.0, 1.0])\n",
      "    pylab.ylim([0.0, 1.0])\n",
      "    pylab.xlabel('Recall')\n",
      "    pylab.ylabel('Precision')\n",
      "    pylab.title('P/R curve (AUC=%0.2f)' % auc_score)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import StratifiedShuffleSplit\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "from sklearn.metrics import precision_recall_curve, auc\n",
      "import sklearn.metrics as metrics\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.svm import SVC\n",
      "\n",
      "def test_model(clf, samples_test, labels_test, print_scores = False):\n",
      "        predictions = clf.predict(samples_test)\n",
      "        precision, recall, f_score, support = metrics.precision_recall_fscore_support(labels_test, predictions, beta=0.33)\n",
      "        area = auc(recall, precision)        \n",
      "        if print_scores:\n",
      "            print(\"f_score:\\t\\t%.5f\"%(f_score[1]))       # just capture the score for our minority target label, not the majority label\n",
      "            print(\"recall:\\t\\t\\t%.5f\"%(recall[1]))\n",
      "            print(\"precision:\\t\\t%.5f\"%(precision[1]))\n",
      "            #print(\"AUC:\\t\\t%.5f\"%(area))\n",
      "        return precision[1], recall[1], f_score[1], area # just capture the score for our minority target label, not the majority label\n",
      "\n",
      "def train_model(clf_factory, samples, labels, print_scores = False):\n",
      "    samples_df = pandas.DataFrame(samples) # more familiar working with Pandas dataframes\n",
      "    cross_validation = StratifiedKFold(labels, n_folds=10) # Use Stratified types here due to the imbalance in the labels\n",
      "    precisions, recalls, f_scores, AUCs = [], [], [], []\n",
      "    for train, test in cross_validation:\n",
      "        samples_train, labels_train = samples_df.iloc[train], labels[train]\n",
      "        samples_test, labels_test = samples_df.iloc[test], labels[test]\n",
      "        clf = clf_factory()\n",
      "        %time clf.fit(samples_train, labels_train)\n",
      "        precision, recall, f_score, area = test_model(clf, samples_test, labels_test, print_scores)\n",
      "        precisions.append(precision) \n",
      "        recalls.append(recall)\n",
      "        AUCs.append(area)\n",
      "        f_scores.append(f_score)     \n",
      "    print(\"f_score:\\t\\tMean=%.5f\\t\\tStddev=%.5f\"%(np.mean(f_scores), np.std(f_scores)))\n",
      "    print(\"recall:\\t\\t\\tMean=%.5f\\t\\tStddev=%.5f\"%(np.mean(recalls), np.std(recalls)))\n",
      "    print(\"precision:\\t\\tMean=%.5f\\t\\tStddev=%.5f\"%(np.mean(precisions), np.std(precisions)))\n",
      "    # print(\"AUC:\\t\\tMean=%.5f\\t\\tStddev=%.5f\"%(np.mean(AUCs), np.std(AUCs)))\n",
      "\n",
      "def clf_factory(): return GaussianNB()\n",
      "train_model(clf_factory, samples, labels)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "global name 'GaussianNB' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-5-d12a83378d75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclf_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf_factory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-5-d12a83378d75>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(clf_factory, samples, labels, print_scores)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0msamples_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msamples_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0msamples_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msamples_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time clf.fit(samples_train, labels_train)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marea\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-5-d12a83378d75>\u001b[0m in \u001b[0;36mclf_factory\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# print(\"AUC:\\t\\tMean=%.5f\\t\\tStddev=%.5f\"%(np.mean(AUCs), np.std(AUCs)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mclf_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf_factory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: global name 'GaussianNB' is not defined"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## n.b. Can't use MultinomialNB on normalised data, as it won't accept negative values\n",
      "#from sklearn.naive_bayes import MultinomialNB\n",
      "#nb_m = MultinomialNB()\n",
      "#test_classifier(nb_m, samples_train, labels_train, samples_test, labels_test)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import GaussianNB\n",
      "nb_g = GaussianNB()\n",
      "test_classifier(nb_g, samples_train, labels_train, samples_test, labels_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import BernoulliNB\n",
      "nb_b = BernoulliNB()\n",
      "test_classifier(nb_b, samples_train, labels_train, samples_test, labels_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "rf = RandomForestClassifier(n_estimators = 2)\n",
      "test_classifier(rf, samples_train, labels_train, samples_test, labels_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Attributed to \"Building Machine Learning Systems with Python\", 2013 Richert, W. and Coelho, L., Packt Publishing, p129\n",
      "from sklearn.metrics import precision_recall_curve, auc\n",
      "from sklearn.cross_validation import ShuffleSplit\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "\n",
      "import sklearn.ensemble as sk\n",
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "def clf_factory():\n",
      "    clf = GaussianNB()\n",
      "    #clf = MultinomialNB()\n",
      "    #clf = neighbors.KNeighborsClassifier(n_neighbors=2)\n",
      "    #clf = SVC(kernel=\"poly\", degree=3, probability=True)\n",
      "    return clf\n",
      "\n",
      "def train_model(clf_factory, X, Y):\n",
      "  # setting random_state to get deterministic behavior\n",
      "  cross_val = ShuffleSplit(X.shape[0], n_iter=10, test_size=0.3, random_state=0)\n",
      "  # cross_validation = StratifiedShuffleSplit(labels, n_iter=10, test_size=0.3, random_state=0)\n",
      "  scores = []\n",
      "  pr_scores = []\n",
      "  precisions, recalls, thresholds = [], [], []\n",
      "  #have to convert X to a pandas DataFrame, as I don't seem to be able to index it correctly as a numpy array\n",
      "  x_df = pandas.DataFrame(X)\n",
      "  for train, test in cross_val:\n",
      "    X_train, y_train = x_df.iloc[train], Y[train]\n",
      "    X_test, y_test = x_df.iloc[test], Y[test]\n",
      "    clf = clf_factory()\n",
      "    clf.fit(X_train, y_train)\n",
      "    predictions = clf.predict(X_test)\n",
      "    \n",
      "    proba = clf.predict_proba(X_test)\n",
      "    precision, recall, pr_thresholds = precision_recall_curve(y_test, proba[:,1])\n",
      "    pr_scores.append(auc(recall, precision))\n",
      "    precisions.append(precision)\n",
      "    recalls.append(recall)\n",
      "\n",
      "  scores_to_sort = pr_scores\n",
      "  median = np.argsort(scores_to_sort)[len(scores_to_sort) / 2]\n",
      "  summary = (np.mean(scores), np.std(scores), np.mean(pr_scores), np.std(pr_scores))\n",
      "  print \"%.3f\\t%.3f\\t%.3f\\t%.3f\"%summary\n",
      "  plot_precision_recall_curve(pr_scores[median], precisions[median], recalls[median])\n",
      "  summary = (np.mean(scores), np.std(scores), np.mean(pr_scores), np.std(pr_scores))\n",
      "  print \"%.3f\\t%.3f\\t%.3f\\t%.3f\\t\" % summary\n",
      "  print('The classifier has a P/R AUC of score of %0.2f with a standard deviation of %0.4f' %(summary[2:4]))\n",
      "\n",
      "%time train_model(clf_factory, samples, labels)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Pull out fearture importances from random forest and bar chart them"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "http://nbviewer.ipython.org/github/herrfz/dataanalysis/blob/master/assignment2/samsung_data_prediction_submitted.ipynb"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.ensemble as ensemble\n",
      "rfc = ensemble.RandomForestClassifier(n_estimators=300, oob_score=True)\n",
      "%time model = rfc.fit(samples_train, labels_train)\n",
      "\n",
      "test_pred = rfc.predict(samples_test)\n",
      "import sklearn.metrics as metrics\n",
      "print(\"Accuracy = %f\" %(metrics.accuracy_score(labels_test,test_pred)))\n",
      "print(\"Precision = %f\" %(metrics.precision_score(labels_test,test_pred)))\n",
      "print(\"Recall = %f\" %(metrics.recall_score(labels_test,test_pred)))\n",
      "print(\"F1 score = %f\" %(metrics.f1_score(labels_test,test_pred)))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Grid Searches"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# bookmark\n",
      "\n",
      "# PROPER CORSS VALIDATION\n",
      "# \n",
      "# # from http://scikit-learn.org/stable/auto_examples/feature_selection/plot_rfe_with_cross_validation.html\n",
      "# \n",
      "# from sklearn.svm import SVC\n",
      "# from sklearn.cross_validation import StratifiedKFold\n",
      "# from sklearn.feature_selection import RFECV\n",
      "# from sklearn.datasets import make_classification\n",
      "# \n",
      "# # Build a classification task using 3 informative features\n",
      "# #X, y = make_classification(n_samples=1000, n_features=25, n_informative=3,\n",
      "# #                           n_redundant=2, n_repeated=0, n_classes=8,\n",
      "# #                           n_clusters_per_class=1, random_state=0)\n",
      "# \n",
      "# X = samples_train\n",
      "# y = labels_train\n",
      "# \n",
      "# # Create the RFE object and compute a cross-validated score.\n",
      "# svc = SVC(kernel=\"linear\")\n",
      "# # The \"accuracy\" scoring is proportional to the number of correct\n",
      "# # classifications\n",
      "# %time rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(y, 2), scoring='precision')\n",
      "# %time rfecv.fit(X, y)\n",
      "# \n",
      "# print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
      "# \n",
      "# # Plot number of features VS. cross-validation scores\n",
      "# pyplot.figure()\n",
      "# pyplot.xlabel(\"Number of features selected\")\n",
      "# pyplot.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
      "# pyplot.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
      "# pyplot.show()\n",
      "# "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Attributed to: http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "from sklearn import svm, datasets\n",
      "from sklearn.metrics import precision_recall_curve\n",
      "from sklearn.metrics import average_precision_score\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.preprocessing import label_binarize\n",
      "from sklearn.multiclass import OneVsRestClassifier\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "n_classes = 2\n",
      "\n",
      "labels_score = best_clf.fit(samples_train, labels_train).decision_function(samples_test)\n",
      "\n",
      "# Compute Precision-Recall and plot curve\n",
      "precision = dict()\n",
      "recall = dict()\n",
      "average_precision = dict()\n",
      "for i in range(n_classes):\n",
      "    precision[i], recall[i], _ = precision_recall_curve(labels_test[:, i],\n",
      "                                                        labels_score[:, i])\n",
      "    average_precision[i] = average_precision_score(labels_test[:, i], labels_score[:, i])\n",
      "\n",
      "# Compute micro-average ROC curve and ROC area\n",
      "precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(labels_test.ravel(),\n",
      "    labels_score.ravel())\n",
      "average_precision[\"micro\"] = average_precision_score(labels_test, labels_score,\n",
      "                                                     average=\"micro\")\n",
      "\n",
      "# Plot Precision-Recall curve\n",
      "plt.clf()\n",
      "plt.plot(recall[0], precision[0], label='Precision-Recall curve')\n",
      "plt.xlabel('Recall')\n",
      "plt.ylabel('Precision')\n",
      "plt.ylim([0.0, 1.05])\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.title('Precision-Recall example: AUC={0:0.2f}'.format(average_precision[0]))\n",
      "plt.legend(loc=\"lower left\")\n",
      "plt.show()\n",
      "\n",
      "# Plot Precision-Recall curve for each class\n",
      "plt.clf()\n",
      "plt.plot(recall[\"micro\"], precision[\"micro\"],\n",
      "         label='micro-average Precision-recall curve (area = {0:0.2f})'\n",
      "               ''.format(average_precision[\"micro\"]))\n",
      "for i in range(n_classes):\n",
      "    plt.plot(recall[i], precision[i],\n",
      "             label='Precision-recall curve of class {0} (area = {1:0.2f})'\n",
      "                   ''.format(i, average_precision[i]))\n",
      "\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.ylim([0.0, 1.05])\n",
      "plt.xlabel('Recall')\n",
      "plt.ylabel('Precision')\n",
      "plt.title('Extension of Precision-Recall curve to multi-class')\n",
      "plt.legend(loc=\"lower right\")\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}