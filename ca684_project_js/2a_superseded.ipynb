{
 "metadata": {
  "name": "",
  "signature": "sha256:044195ce050b8eba972187f5ba1cde7647fb448efb13534b6f6ed755b65873ed"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# special IPython command to prepare the notebook for matplotlib\n",
      "%matplotlib inline \n",
      "\n",
      "import numpy as np\n",
      "import pandas\n",
      "from matplotlib import pyplot\n",
      "from matplotlib import pylab\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn import preprocessing\n",
      "from sklearn.lda import LDA\n",
      "from sklearn.cross_validation import train_test_split\n",
      "import scipy.stats as stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataset = pandas.read_csv(\"./dataset_v6.csv\")\n",
      "print 'Total samples & features in original dataset: ' + str(dataset.shape)\n",
      "\n",
      "target_label = 'Lbl: Poor Hosp Rating 1SD'\n",
      "#target_label = 'Lbl: Poor ER Rating 1SD'\n",
      "#target_label = 'Lbl: Poor Pain Rating 1SD'\n",
      "#target_label = 'Lbl: Poor Drugs Rating 1SD'\n",
      "\n",
      "# TODO: remove\n",
      "#dataset = dataset[dataset[target_label] != 1].index # works... now how to select nulls?\n",
      "#dataset = dataset[dataset[target_label].notnull()].index # works... now how to select all the fields, not just this one?\n",
      "#dataset = dataset[dataset[target_label].notnull()] # Works :-)\n",
      "\n",
      "# Strip out any rows where there is no label to train or test with\n",
      "dataset = dataset[dataset[target_label].notnull()]\n",
      "\n",
      "# keep the agency and behavior fields we're interested in (exclude things like patient outcomes, phone numbers, addresses, etc)\n",
      "samples = dataset[[\n",
      "    'Offers Nursing Care Services',\n",
      "    'Offers Physical Therapy Services',\n",
      "    'Offers Occupational Therapy Services',\n",
      "    'Offers Speech Pathology Services',\n",
      "    'Offers Medical Social Services',\n",
      "    'Offers Home Health Aide Services',\n",
      "\n",
      "    'How often the home health team began their patients care in a timely manner',\n",
      "    'How often the home health team taught patients (or their family caregivers) about their drugs',\n",
      "    'How often the home health team checked patients risk of falling',\n",
      "    'How often the home health team checked patients for depression',\n",
      "    'How often the home health team made sure that their patients have received a flu shot for the current flu season.',\n",
      "    'How often the home health team made sure that their patients have received a pneumococcal vaccine (pneumonia shot).',\n",
      "    'With diabetes - how often the home health team got doctors orders and gave foot care and taught patients about foot care',\n",
      "    'How often the home health team checked patients for pain',\n",
      "    'How often the home health team treated their patients pain',\n",
      "    'How often the home health team took doctor-ordered action to prevent pressure sores (bed sores)',\n",
      "    'How often the home health team checked patients for the risk of developing pressure sores (bed sores)',\n",
      "\n",
      "    'Count of non-reported behaviours',\n",
      "    'Count of non-reported outcomes',\n",
      "    'Non-trad Chronic'\n",
      "]]\n",
      "\n",
      "# (1) reshape the label matrix to be flat\n",
      "# (2) change the boolean {false, true} values into {0,1} as sklearn modules expect\n",
      "labels = np.reshape(dataset[target_label].astype(int), -1)\n",
      "\n",
      "print 'Target label: [' + target_label + ']'\n",
      "print 'There are %1i samples in the dataset (having eliminated samples where the target label was null).' % (dataset.shape[0])\n",
      "print 'There are %1s poorly performing agencies identified in the dataset by the label \\'%2s\\'.' % ((sum(p == 1 for p in labels)), target_label)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total samples & features in original dataset: (10106, 44)\n",
        "Target label: [Lbl: Poor Hosp Rating 1SD]\n",
        "There are 8965 samples in the dataset (having eliminated samples where the target label was null).\n",
        "There are 1099 poorly performing agencies identified in the dataset by the label 'Lbl: Poor Hosp Rating 1SD'."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Plotting Functions (for use in later sections)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "_General functions for graphs throughout this notebook_"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# special IPython command to prepare the notebook for matplotlib\n",
      "%matplotlib inline\n",
      "from matplotlib import pyplot\n",
      "from matplotlib import pylab\n",
      "\n",
      "data_labels, markers, colours, alphas = [0, 1], ['o', 'o'], ['b', 'r'], [0.3, 0.6]\n",
      "\n",
      "def scatterplot(xaxis, yaxis, y, title = '', xlabel = 'X', ylabel = 'Y'):\n",
      "    for label, marker, colour, a in zip(data_labels, markers, colours, alphas):\n",
      "        pyplot.scatter(xaxis[y == label], yaxis[y == label], c=colour, s = 30, cmap=plt.cm.bwr, marker=marker, alpha=a, edgecolors='none')\n",
      "    pyplot.xlabel(xlabel)\n",
      "    pyplot.ylabel(ylabel)\n",
      "    pyplot.title(title)\n",
      "    pyplot.legend(loc='best')\n",
      "    pyplot.show()\n",
      "\n",
      "# Attributed to \"Building Machine Learning Systems with Python\", 2013 Richert, W. and Coelho, L., Packt Publishing\n",
      "def plot_precision_recall_curve(auc_score, precision, recall):\n",
      "    pylab.clf()\n",
      "    pylab.figure(num=None, figsize=(5, 4))\n",
      "    pylab.grid(True)\n",
      "    pylab.fill_between(recall, precision, alpha=0.5)\n",
      "    pylab.plot(recall, precision, lw=1)\n",
      "    pylab.xlim([0.0, 1.0])\n",
      "    pylab.ylim([0.0, 1.0])\n",
      "    pylab.xlabel('Recall')\n",
      "    pylab.ylabel('Precision')\n",
      "    pylab.title('P/R curve (AUC=%0.2f)' % auc_score)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# n.b. this switches samples from a pandas DataFrame to a NumPy array\n",
      "samples = preprocessing.normalize(samples.astype(float))\n",
      "samples = preprocessing.scale(samples)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# put test data aside\n",
      "samples_train, samples_test, labels_train, labels_test = train_test_split(\n",
      "    samples,labels, test_size=0.5, random_state=2)\n",
      "\n",
      "print 'Samples & features in the training set: ' + str(samples_train.shape)\n",
      "print 'Number of poor outcomes in the training dataset: ' + str(sum(p == 1 for p in labels_train))\n",
      "\n",
      "print 'Samples & features in the test set: ' + str(samples_test.shape)\n",
      "print 'Number of poor outcomes in the test dataset: ' + str(sum(p == 1 for p in labels_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Samples & features in the training set: (4482L, 20L)\n",
        "Number of poor outcomes in the training dataset: 537\n",
        "Samples & features in the test set: (4483L, 20L)\n",
        "Number of poor outcomes in the test dataset: 562\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "@-* NEW CODE *-@"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "beta=0.25 # our performance metric rates recall being 1/4 as important as precision\n",
      "%run train_model.py\n",
      "%run grid_search.py\n",
      "# plot_learning_curve() function comes from http://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html#example-model-selection-plot-learning-curve-py\n",
      "%run plot_learning_curve.py\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "KNN 1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "def clf_factory(): return KNeighborsClassifier()\n",
      "def knn_grid_search(debug=False):\n",
      "    grid_hyperparameters = [{'n_neighbors' : range(1, 6), 'weights' : ['uniform', 'distance']}]\n",
      "    best_clf = grid_search(clf_factory, grid_hyperparameters, samples_train, labels_train, 5)\n",
      "    print best_clf\n",
      "    %time train_model(best_clf, samples_train, labels_train, 5, beta, debug)\n",
      "    precision, recall, f_score, area = test_model(best_clf, samples_test, labels_test, debug=debug)\n",
      "    %time plot_learning_curve(best_clf, type(best_clf), samples, labels, ylim=(0, 1), n_folds=5, n_jobs=-1, scoring=scoring)\n",
      "\n",
      "# TODO: REMOVE - Run time is about 30s\n",
      "#knn_grid_search(debug=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Decision Tree"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.tree import DecisionTreeClassifier\n",
      "def clf_factory(): return DecisionTreeClassifier(random_state=0)\n",
      "def dt_grid_search(debug=False):\n",
      "    grid_hyperparameters = [{\"max_depth\": range(2, 30)}]\n",
      "    #grid_hyperparameters = [{\"max_depth\": range(2, 30), 'class_weight': ['auto', None]}] # can't use auto, as it's a scikit .16 feature\n",
      "    best_clf = grid_search(clf_factory, grid_hyperparameters, samples_train, labels_train, 5)\n",
      "    print best_clf\n",
      "    %time train_model(best_clf, samples_train, labels_train, 5, beta, debug)\n",
      "    %time precision, recall, f_score, area = test_model(best_clf, samples_test, labels_test, debug)\n",
      "    %time plot_learning_curve(best_clf, type(best_clf), samples, labels, ylim=(0, 1), n_folds=5, n_jobs=-1, scoring=scoring)\n",
      "\n",
      "# TODO: REMOVE - Run time is about 30s\n",
      "#dt_grid_search(debug=True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Logistic Regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "def clf_factory(): return LogisticRegression(C=1e5, class_weight='auto')\n",
      "def lr_grid_search(debug=False):\n",
      "    grid_hyperparameters = {'C': np.logspace(-5, 5, 100), 'class_weight': ['auto', None]}\n",
      "    best_clf = grid_search(clf_factory, grid_hyperparameters, samples_train, labels_train, 5)\n",
      "    print best_clf\n",
      "    %time train_model(best_clf, samples_train, labels_train, 5, beta, debug)\n",
      "    %time precision, recall, f_score, area = test_model(best_clf, samples_test, labels_test, debug)\n",
      "    %time plot_learning_curve(best_clf, type(best_clf), samples, labels, ylim=(0, 1), n_folds=5, n_jobs=-1, scoring=scoring)\n",
      "\n",
      "# TODO: REMOVE - Run time is about 40s\n",
      "#lr_grid_search(debug=True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "AdaBoost"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "<font color='red'>** TODO ** DO PROPER GRID SEARCH, RUN OVER DINS (OR OVERNIGHT) </font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "\n",
      "def clf_factory(): return AdaBoostClassifier(DecisionTreeClassifier(max_depth=7),\n",
      "                         algorithm=\"SAMME\",\n",
      "                         n_estimators=150)\n",
      "\n",
      "def ab_grid_search(debug=False):\n",
      "    grid_hyperparameters = {'n_estimators': [100, 200, 300, 400],\n",
      "                      'base_estimator__max_depth': [1, 5, 10, 15],\n",
      "                      'algorithm': ('SAMME', 'SAMME.R')}\n",
      "    #grid_hyperparameters = {'n_estimators': [100, 200, 300, 400]}\n",
      "    best_clf = grid_search(clf_factory, grid_hyperparameters, samples_train, labels_train, 5)\n",
      "    print best_clf\n",
      "    %time train_model(best_clf, samples_train, labels_train, 5, beta, debug) # much more expensive, can only afford 5 folds\n",
      "    %time precision, recall, f_score, area = test_model(best_clf, samples_test, labels_test, debug)\n",
      "    %time plot_learning_curve(best_clf, type(best_clf), samples, labels, ylim=(0, 1), n_folds=5, n_jobs=-1, scoring=scoring)\n",
      "\n",
      "# TODO: REMOVE - Run time is in excess of an hour\n",
      "#ab_grid_search(debug=True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<pre>\n",
      "Best combination of hyperparameters for this classifier:\n",
      "AdaBoostClassifier(\n",
      "          algorithm='SAMME.R',\n",
      "          base_estimator=DecisionTreeClassifier(compute_importances=None, criterion='gini',\n",
      "            max_depth=1, max_features=None, max_leaf_nodes=None,\n",
      "            min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
      "            random_state=None, splitter='best'),\n",
      "          learning_rate=1.0, n_estimators=300, random_state=None)\n",
      "\n",
      "f_score:      Mean=0.20188    Stddev=0.08958\n",
      "precision:    Mean=0.28667    Stddev=0.13112\n",
      "recall:       Mean=0.03541    Stddev=0.01498\n",
      "</pre>\n",
      "\n",
      "![Alt text](./ab_learning_curve.png \"Fig. TODO: AdaBoost Learning Curve.\")\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "SVC"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import SVC\n",
      "#def clf_factory(): return SVC()\n",
      "def clf_factory(): return SVC(C=1)\n",
      "\n",
      "def svc_grid_search(debug=False):\n",
      "    #grid_hyperparameters = [{'kernel': ('linear', 'sigmoid', 'rbf'), 'C':[1, 5, 10], 'gamma':[0, 0.001, 0.1]}]\n",
      "    #grid_hyperparameters = [{'kernel': ('linear', 'rbf'), 'C':[1, 5], 'gamma':[0, 0.1]}]\n",
      "    grid_hyperparameters = [{'kernel': ('linear', 'rbf'), 'gamma':[0, 0.1]}]\n",
      "    best_clf = grid_search(clf_factory, grid_hyperparameters, samples_train, labels_train, 5)\n",
      "    print best_clf\n",
      "    %time train_model(best_clf, samples_train, labels_train, 5, beta, debug)\n",
      "    precision, recall, f_score, area = test_model(best_clf, samples_test, labels_test, debug)\n",
      "    %time plot_learning_curve(best_clf, type(best_clf), samples, labels, ylim=(0, 1), n_folds=5, n_jobs=-1, scoring=scoring)\n",
      "\n",
      "# TODO: REMOVE - Run time is between 1 and 2 mins\n",
      "#svc_grid_search(debug=True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import SVC\n",
      "def clf_factory(): return SVC(kernel='poly')\n",
      "\n",
      "def svcp_grid_search(debug=False):\n",
      "    grid_hyperparameters = [{'degree':[2, 3, 4, 5], 'C':[1, 5, 10], 'gamma':[0, 0.001, 0.1]}]\n",
      "    best_clf = grid_search(clf_factory, grid_hyperparameters, samples_train, labels_train, 5)\n",
      "    print best_clf\n",
      "    %time train_model(best_clf, samples_train, labels_train, 5, beta, debug)\n",
      "    precision, recall, f_score, area = test_model(best_clf, samples_test, labels_test, debug)\n",
      "    %time plot_learning_curve(best_clf, type(best_clf), samples, labels, ylim=(0, 1), n_folds=5, n_jobs=-1, scoring=scoring)\n",
      "\n",
      "# TODO: REMOVE - Run time is over an hour\n",
      "# svcp_grid_search(debug=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<pre>\n",
      "Best combination of hyperparameters for this classifier:\n",
      "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0, degree=2, gamma=0.1,\n",
      "  kernel='poly', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "\n",
      "f_score:      Mean=0.19681    Stddev=0.11846\n",
      "precision:    Mean=0.39619    Stddev=0.22941\n",
      "recall:       Mean=0.02238    Stddev=0.01401\n",
      "</pre>\n",
      "\n",
      "![Alt text](./svc_learning_curve.png \"Fig. TODO: SVM Learning Curve.\")\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#grid.grid_scores_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    }
   ],
   "metadata": {}
  }
 ]
}